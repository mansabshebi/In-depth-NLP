{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform standard imports\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp=spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple Doc object\n",
    "doc=nlp(u'the quick brown fox jumped over the lazy dog\"s back.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VBD\n"
     ]
    }
   ],
   "source": [
    "print(doc[4].tag_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VERB\n"
     ]
    }
   ],
   "source": [
    "print(doc[4].pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the        DET        DT         determiner\n",
      "quick      ADJ        JJ         adjective \n",
      "brown      PROPN      NNP        noun, proper singular\n",
      "fox        PROPN      NNP        noun, proper singular\n",
      "jumped     VERB       VBD        verb, past tense\n",
      "over       ADP        IN         conjunction, subordinating or preposition\n",
      "the        DET        DT         determiner\n",
      "lazy       ADJ        JJ         adjective \n",
      "dog\"s      NOUN       NN         noun, singular or mass\n",
      "back       ADV        RB         adverb    \n",
      ".          PUNCT      .          punctuation mark, sentence closer\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(f\"{token.text:10} {token.pos_:10} {token.tag_:10} {spacy.explain(token.tag_):10}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=nlp(u'I read a book on nlp')\n",
    "doc1=nlp(u'I have read books on nlp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read       VERB       VBD        verb, past tense\n"
     ]
    }
   ],
   "source": [
    "token=doc[1]\n",
    "print(f\"{token.text:10} {token.pos_:10} {token.tag_:10} {spacy.explain(token.tag_):10}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read       VERB       VBN        verb, past participle\n"
     ]
    }
   ],
   "source": [
    "token=doc1[2]\n",
    "print(f\"{token.text:10} {token.pos_:10} {token.tag_:10} {spacy.explain(token.tag_):10}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=nlp(u'the quick brown fox jumped over the lazy dog\"s back.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "POS_counts=doc.count_by(spacy.attrs.POS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{90: 2, 84: 2, 96: 2, 100: 1, 85: 1, 92: 1, 86: 1, 97: 1}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "POS_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ADJ'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.vocab[84].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84 ADJ       2\n",
      "85 ADP       1\n",
      "86 ADV       1\n",
      "90 DET       2\n",
      "92 NOUN      1\n",
      "96 PROPN     2\n",
      "97 PUNCT     1\n",
      "100 VERB      1\n"
     ]
    }
   ],
   "source": [
    "for k,v in sorted(POS_counts.items()):\n",
    "    print(f\"{k} {doc.vocab[k].text:{10}}{v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Named Entity Recognition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_ents(doc):\n",
    "    if doc.ents:\n",
    "        for ent in doc.ents:\n",
    "            print(ent.text+' - '+ent.label_+' - '+str(spacy.explain(ent.label_)))\n",
    "    else:\n",
    "        print('no entity found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=nlp(u'hi! how are you?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no entity found\n"
     ]
    }
   ],
   "source": [
    "show_ents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=nlp(u'May i go to Washington DC next May to see the washington monument?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Washington DC - GPE - Countries, cities, states\n",
      "next May - DATE - Absolute or relative dates or periods\n",
      "washington - GPE - Countries, cities, states\n"
     ]
    }
   ],
   "source": [
    "show_ents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 - MONEY - Monetary values, including unit\n",
      "Windows - PRODUCT - Objects, vehicles, foods, etc. (not services)\n"
     ]
    }
   ],
   "source": [
    "doc=nlp(u'Can i have please $500 of Windows stocks?')\n",
    "show_ents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UK - GPE - Countries, cities, states\n",
      "6 million dollars - MONEY - Monetary values, including unit\n"
     ]
    }
   ],
   "source": [
    "doc=nlp(u'Tesla to build UK factory for 6 million dollars')\n",
    "show_ents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import Span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "ORG=doc.vocab.strings[u'ORG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "383"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ORG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_entity=Span(doc,0,1,label=ORG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.ents=list(doc.ents)+[new_entity]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla - ORG - Companies, agencies, institutions, etc.\n",
      "UK - GPE - Countries, cities, states\n",
      "6 million dollars - MONEY - Monetary values, including unit\n"
     ]
    }
   ],
   "source": [
    "show_ents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=nlp(u'our company created a vaccum-cleaner'\n",
    "       u\"this new vaccum cleaner is the best.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vaccum - ORG - Companies, agencies, institutions, etc.\n"
     ]
    }
   ],
   "source": [
    "show_ents(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentence Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=nlp(u\"This is the first sentance.This is the second sentance.This is the third sentance.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the first sentance.\n",
      "This is the second sentance.\n",
      "This is the third sentance.\n"
     ]
    }
   ],
   "source": [
    "for sentence in doc.sents:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[This is the first sentance.,\n",
       " This is the second sentance.,\n",
       " This is the third sentance.]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(doc.sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=nlp(u'\"management rules; people work\" -vaibhav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"management rules; people work\" -vaibhav\n"
     ]
    }
   ],
   "source": [
    "for sentence in doc.sents:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add a segmentation rule\n",
    "def set_custom_boundary(doc):\n",
    "    for token in doc[:-1]:\n",
    "        if token.text==';':\n",
    "            doc[token.i+1].is_sent_start=True\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tagger', 'set_custom_boundary', 'parser', 'ner']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nlp.add_pipe(set_custom_boundary,before='parser')\n",
    "\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"management rules;\n",
      "people work\" -vaibhav\n"
     ]
    }
   ],
   "source": [
    "doc=nlp(u'\"management rules; people work\" -vaibhav')\n",
    "for sentence in doc.sents:\n",
    "    print(sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
